{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527228f6",
   "metadata": {},
   "source": [
    "#### **Cell 1: Imports**\n",
    "*Purpose: Import all necessary libraries for data handling, modeling, and experiment tracking.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39324c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard ML libraries for data loading, splitting, and modeling.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# MLflow is the key library for experiment tracking.\n",
    "# We import the main library and the specific 'sklearn' flavor for auto-logging.\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f2618",
   "metadata": {},
   "source": [
    "#### **Cell 2: Load and Prepare Data**\n",
    "*Purpose: Load a sample dataset and split it into training and testing sets, a standard practice in any ML workflow.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4758ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and split successfully.\n",
      "Training set size: 120 samples\n",
      "Test set size: 30 samples\n"
     ]
    }
   ],
   "source": [
    "# Load a well-known sample dataset for this demonstration.\n",
    "iris = load_iris()\n",
    "\n",
    "# Splitting the data is a critical step to prevent the model from being evaluated\n",
    "# on the same data it was trained on, which ensures a fair assessment of its performance.\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data loaded and split successfully.\")\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e70d2",
   "metadata": {},
   "source": [
    "#### **Cell 3: Train Model and Log Experiment with MLflow**\n",
    "*Purpose: This is the core of the MLOps workflow. We train a model and meticulously log every important piece of information to ensure the experiment is fully reproducible.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d33a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/11 09:21:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/06/11 09:21:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 1.0\n",
      "Run successfully logged to MLflow.\n",
      "MLflow Run ID: 18a4185da0104d5f97fa36b92d445d8e\n"
     ]
    }
   ],
   "source": [
    "# By wrapping our training run in 'with mlflow.start_run()', we ensure that\n",
    "# all parameters, metrics, and the model artifact are logged to a single, organized run.\n",
    "# This is the foundation of experiment tracking.\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # --- 1. Log Parameters ---\n",
    "    # We explicitly log the hyperparameters used for this training run.\n",
    "    # If we change these later, we can compare runs to see how it affected performance.\n",
    "    solver = 'liblinear'\n",
    "    random_state = 42\n",
    "    mlflow.log_param(\"solver\", solver)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "    \n",
    "    # --- 2. Train the Model ---\n",
    "    # Standard scikit-learn model training.\n",
    "    lr = LogisticRegression(solver=solver, random_state=random_state)\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # --- 3. Evaluate and Log Metrics ---\n",
    "    # We evaluate the model on the unseen test set.\n",
    "    y_pred = lr.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # We log the resulting performance metric. This is our key indicator of model quality.\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # --- 4. Log the Model Artifact ---\n",
    "    # This is the most crucial step for deployment. MLflow packages the trained model\n",
    "    # along with its dependencies (e.g., scikit-learn version) into a portable format.\n",
    "    # This packaged artifact can then be easily deployed as an API without compatibility issues.\n",
    "    mlflow.sklearn.log_model(lr, \"model\")\n",
    "    \n",
    "    # --- 5. Print Results ---\n",
    "    print(f\"Model Accuracy: {accuracy}\")\n",
    "    print(\"Run successfully logged to MLflow.\")\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    print(f\"MLflow Run ID: {run_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
